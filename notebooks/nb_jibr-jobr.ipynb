{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d315d4399fa140af96b6915c42ff8bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23924697924645a2be8b95d2076df14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m PYDEVD_DISABLE_FILE_VALIDATION \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mPYDEVD_DISABLE_FILE_VALIDATION\n\u001b[0;32m     23\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(SALESFORCE, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSALESFORCE\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m####(SNAP)  ##(SHARDS) #(MODEL)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Instantiate model configuration\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# model_config = AutoConfig.from_pretrained(Path(SHARDS))\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# tokenizer = AutoTokenizer.from_pretrained(SALESFORCE)\u001b[39;00m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\modeling_utils.py:3483\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3480\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   3481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m   3482\u001b[0m     \u001b[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 3483\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3499\u001b[0m     is_safetensors_available()\n\u001b[0;32m   3500\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3502\u001b[0m ):\n\u001b[0;32m   3503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\utils\\hub.py:1025\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\utils\\hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\file_download.py:1457\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1455\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[1;32m-> 1457\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\file_download.py:524\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[0;32m    522\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[0;32m    526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\urllib3\\response.py:1033\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1033\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1036\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\urllib3\\response.py:925\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 925\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    927\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\urllib3\\response.py:852\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    849\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 852\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    854\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    861\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\urllib3\\response.py:835\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mD:\\__python__\\Python312\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mD:\\__python__\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\__python__\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mD:\\__python__\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LLM to synthesize job descriptions from freeform text.\n",
    "Uses \"Salesforce/xgen-7b-8k-inst\" LLM from Hugging Face.\n",
    "\"\"\"\n",
    "\n",
    "# Load packages\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline #AutoConfig, \n",
    "# import streamlit as st\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user-defined modules\n",
    "from config import AppConfig\n",
    "\n",
    "# Instantiate app configuration\n",
    "config = AppConfig()\n",
    "\n",
    "SHARDS = config.SHARDS\n",
    "\n",
    "\n",
    "MODEL = config.MODEL\n",
    "SNAP = config.SNAP\n",
    "SALESFORCE = config.SALESFORCE\n",
    "PYDEVD_DISABLE_FILE_VALIDATION = config.PYDEVD_DISABLE_FILE_VALIDATION\n",
    "\n",
    "# Instantiate model configuration\n",
    "# model_config = AutoConfig.from_pretrained(Path(SHARDS))\n",
    "\n",
    "# config = AutoConfig.from_pretrained(CONFIG)\n",
    "# model = AutoModel.from_pretrained(SNAP)  ##[SHARD1, SHARD2, SHARD3]) #, config=config)\n",
    "# # model = AutoModel.from_config(model_config)\n",
    "\n",
    "# # # model.load_state_dict(torch.load(Path(config.SHARDS)))  ##, map_location=\"cpu\"))\n",
    "# # # print(model)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(SALESFORCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(SALESFORCE, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(SALESFORCE)  ####(SNAP)  ##(SHARDS) #(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=model, tokenizer=tokenizer)  ## config=model_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=model, tokenizer=tokenizer)  ## config=model_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './.cache/models--Salesforce--xgen-7b-8k-inst/snapshots/943f44c31ffc2667253efca08a0cae7963333ce5'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\utils\\hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './.cache/models--Salesforce--xgen-7b-8k-inst/snapshots/943f44c31ffc2667253efca08a0cae7963333ce5'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create pipeline for modeling\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./.cache/models--Salesforce--xgen-7b-8k-inst/snapshots/943f44c31ffc2667253efca08a0cae7963333ce5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m####, config=model_config)\u001b[39;00m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:747\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m     pretrained_model_name_or_path \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig) \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 747\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\utils\\hub.py:450\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: './.cache/models--Salesforce--xgen-7b-8k-inst/snapshots/943f44c31ffc2667253efca08a0cae7963333ce5'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "# Create pipeline for modeling\n",
    "pipe = pipeline(\"summarization\", model=\"./cache/models--Salesforce--xgen-7b-8k-inst/snapshots/943f44c31ffc2667253efca08a0cae7963333ce5\")  ####, config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize text into a job description.\n",
    "@st.cache_data\n",
    "def summarize(text: str) -> str:\n",
    "    header = \"Application to generate formal job descriptions using Salesforce/xgen LLM for summarization.\"\n",
    "    text = header + \"#### User: Please summarize this into a job description. \\n\\n\" + text + \"\\n\\n####\"\n",
    "\n",
    "    pipe_out = pipe(text)\n",
    "\n",
    "    summary = pipe_out[0][\"summary_text\"]\n",
    "    summary = \"#### Job Description: \".join(pipe_out[0][\"summary_text\"]) \n",
    "                                            ##.split(\"#### Job Description: \")[:2]) + \"\\n\\n####\" + pipe_out[0][\"summary_text\"] + \"\\n\\n####\"  #tokenizer.decode(outputs[0], skip_special_tokens=True)  ##.lstrip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://huggingface.co/\"\n",
    "requests.get(url, verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d518f018afa4bd9bbeaee73afb71566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\schel\\.cache\\huggingface\\hub\\models--Salesforce--xgen-7b-8k-inst. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d64f80c788436091fb42e50983dfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_xgen.py:   0%|          | 0.00/8.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/xgen-7b-8k-inst:\n",
      "- tokenization_xgen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8e3e4af50449c5bc7bfdebbafeb699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/510 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "No GPU found. A GPU is needed for quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/xgen-7b-8k-inst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      3\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalesforce/xgen-7b-8k-inst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32md:\\__python__\\_projects_\\_jibr_jobr\\metro\\Lib\\site-packages\\transformers\\modeling_utils.py:3030\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m   3029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m-> 3030\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m   3032\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   3033\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3034\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3035\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install bitsandbytes`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3036\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Salesforce/xgen-7b-8k-inst\", \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Salesforce/xgen-7b-8k-inst\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    load_in_8bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9945.10 MB. The target location C:\\Users\\schel\\.cache\\huggingface\\hub only has 8839.25 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9945.10 MB. The target location C:\\Users\\schel\\.cache\\huggingface\\hub\\models--Salesforce--xgen-7b-4k-base\\blobs only has 8839.25 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading shards:   0%|          | 0/3 [01:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m summa \u001b[39m=\u001b[39m pipeline(task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSalesforce/xgen-7b-4k-base\u001b[39;49m\u001b[39m\"\u001b[39;49m, revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\pipelines\\__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 870\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    871\u001b[0m         model,\n\u001b[0;32m    872\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    873\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    874\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    875\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    876\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    877\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    878\u001b[0m     )\n\u001b[0;32m    880\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    881\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\pipelines\\base.py:269\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mfrom_pretrained(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    271\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   3126\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[0;32m   3127\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 3128\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[0;32m   3129\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   3130\u001b[0m         resolved_archive_file,\n\u001b[0;32m   3131\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   3132\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   3133\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   3134\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   3135\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   3136\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   3137\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   3138\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   3139\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   3140\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[0;32m   3141\u001b[0m     )\n\u001b[0;32m   3143\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3144\u001b[0m     is_safetensors_available()\n\u001b[0;32m   3145\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(resolved_archive_file, \u001b[39mstr\u001b[39m)\n\u001b[0;32m   3146\u001b[0m     \u001b[39mand\u001b[39;00m resolved_archive_file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.safetensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3147\u001b[0m ):\n\u001b[0;32m   3148\u001b[0m     \u001b[39mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\utils\\hub.py:1052\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m   1050\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1051\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   1053\u001b[0m             pretrained_model_name_or_path,\n\u001b[0;32m   1054\u001b[0m             shard_filename,\n\u001b[0;32m   1055\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1056\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1057\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1058\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1059\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1060\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   1061\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1062\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1063\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   1064\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[0;32m   1065\u001b[0m         )\n\u001b[0;32m   1066\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\utils\\hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    431\u001b[0m         path_or_repo_id,\n\u001b[0;32m    432\u001b[0m         filename,\n\u001b[0;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    443\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:1431\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[1;32m-> 1431\u001b[0m     http_get(\n\u001b[0;32m   1432\u001b[0m         url_to_download,\n\u001b[0;32m   1433\u001b[0m         temp_file,\n\u001b[0;32m   1434\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1435\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1436\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1437\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m   1438\u001b[0m     )\n\u001b[0;32m   1440\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1441\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:551\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    541\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    544\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    545\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[0;32m    550\u001b[0m )\n\u001b[1;32m--> 551\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[0;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    553\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 936\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    938\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    939\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m amt:\n\u001b[0;32m    877\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[1;32m--> 879\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[0;32m    881\u001b[0m flush_decoder \u001b[39m=\u001b[39m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data)\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m    816\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "summa = pipeline(task=\"summarization\", model=\"Salesforce/xgen-7b-4k-base\", revision=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name= \"../models/.cached/models--Salesforce--xgen-7b-4k-base/.no_exist/\", \n",
    "repo_id = \"e5842215153cadc47318560dee2fc044d29b75f0\"\n",
    "model_name = \"Salesforce/xgen-7b-4k-base\"  ## \"pytorch_model-00003-of-00003.bin\"\n",
    "cache_dir = \"../models/.cached/pipe/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9945.10 MB. The target location C:\\Users\\schel\\.cache\\huggingface\\hub only has 9185.90 MB free disk space.\n",
      "  warnings.warn(\n",
      "c:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:979: UserWarning: Not enough free disk space to download the file. The expected file size is: 9945.10 MB. The target location C:\\Users\\schel\\.cache\\huggingface\\hub\\models--Salesforce--xgen-7b-4k-base\\blobs only has 9185.90 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading shards:   0%|          | 0/3 [00:47<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m summarizer \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                        repo_name\u001b[39m=\u001b[39;49m repo_name, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                        repo_id\u001b[39m=\u001b[39;49m repo_id, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                        model\u001b[39m=\u001b[39;49m model_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                        cache_dir\u001b[39m=\u001b[39;49m cache_dir)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\pipelines\\__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 870\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    871\u001b[0m         model,\n\u001b[0;32m    872\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    873\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    874\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    875\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    876\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    877\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    878\u001b[0m     )\n\u001b[0;32m    880\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    881\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\pipelines\\base.py:269\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mfrom_pretrained(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    271\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[0;32m   3126\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[0;32m   3127\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[1;32m-> 3128\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[0;32m   3129\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   3130\u001b[0m         resolved_archive_file,\n\u001b[0;32m   3131\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   3132\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   3133\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   3134\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   3135\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   3136\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   3137\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   3138\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   3139\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   3140\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[0;32m   3141\u001b[0m     )\n\u001b[0;32m   3143\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3144\u001b[0m     is_safetensors_available()\n\u001b[0;32m   3145\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(resolved_archive_file, \u001b[39mstr\u001b[39m)\n\u001b[0;32m   3146\u001b[0m     \u001b[39mand\u001b[39;00m resolved_archive_file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.safetensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3147\u001b[0m ):\n\u001b[0;32m   3148\u001b[0m     \u001b[39mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\utils\\hub.py:1052\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[0;32m   1050\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1051\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   1053\u001b[0m             pretrained_model_name_or_path,\n\u001b[0;32m   1054\u001b[0m             shard_filename,\n\u001b[0;32m   1055\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1056\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1057\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1058\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1059\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1060\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   1061\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1062\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1063\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   1064\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[0;32m   1065\u001b[0m         )\n\u001b[0;32m   1066\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\utils\\hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    431\u001b[0m         path_or_repo_id,\n\u001b[0;32m    432\u001b[0m         filename,\n\u001b[0;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    443\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:1431\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[1;32m-> 1431\u001b[0m     http_get(\n\u001b[0;32m   1432\u001b[0m         url_to_download,\n\u001b[0;32m   1433\u001b[0m         temp_file,\n\u001b[0;32m   1434\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1435\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1436\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1437\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m   1438\u001b[0m     )\n\u001b[0;32m   1440\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1441\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\huggingface_hub\\file_download.py:551\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    541\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    544\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    545\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    549\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[0;32m    550\u001b[0m )\n\u001b[1;32m--> 551\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[0;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    553\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 936\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    938\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    939\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m amt:\n\u001b[0;32m    877\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[1;32m--> 879\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[0;32m    881\u001b[0m flush_decoder \u001b[39m=\u001b[39m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data)\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m    816\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    817\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\site-packages\\urllib3\\response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\textgen\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\",\n",
    "                       repo_name= repo_name, \n",
    "                       repo_id= repo_id, \n",
    "                       model= model_name,\n",
    "                       cache_dir= cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  pipe = pipeline(\"text-generation\", model=\"Salesforce/xgen-7b-4k-base:main\")  ##, n_gqa=4)  ##, revision=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda\\envs\\textgen\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xgen-7b-4k-base\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/xgen-7b-4k-base\", use_auth_token=access_token, cache_dir=\"../models/.cache/\", revision=\"main\")  \n",
    "#token=access_token, revision=\"main\", torch_dtype=torch.bfloat16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlamaTokenizer' from 'transformers' (c:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Use a pipeline as a high-level helper\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m LlamaTokenizer, Llama2ForCausalLM\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# pipe = pipeline(\"text-generation\", model=\"llama2/llama_7b\")  ##, revision=\"main\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSalesforce/xgen-7b-4k-base\u001b[39m\u001b[39m\"\u001b[39m, n_gqa\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)  \u001b[39m##, revision=\"main\")\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LlamaTokenizer' from 'transformers' (c:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from transformers import LlamaTokenizer, Llama2ForCausalLM\n",
    "# pipe = pipeline(\"text-generation\", model=\"llama2/llama_7b\")  ##, revision=\"main\")\n",
    "pipe = pipeline(\"text-generation\", model=\"Salesforce/xgen-7b-4k-base:main\")  ##, n_gqa=4)  ##, revision=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 4\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m LlamaForCausalLM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from config import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LLamaForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mSalesforce/xgen-7b-4k-base\u001b[39m\u001b[39m\"\u001b[39m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LLamaForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mSalesforce/xgen-7b-4k-base/pytorch_model-00001-of-00003.bin\u001b[39m\u001b[39m\"\u001b[39m, token\u001b[39m=\u001b[39maccess_token, torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbfloat16)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(\u001b[39m\"\u001b[39m\u001b[39mtechnical engineering medical devices r&d risk management\u001b[39m\u001b[39m\"\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X62sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sample \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs, max_length\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LLamaForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xgen-7b-4k-base\", trust_remote_code=True)\n",
    "model = LLamaForCausalLM.from_pretrained(\"Salesforce/xgen-7b-4k-base/pytorch_model-00001-of-00003.bin\", token=access_token, torch_dtype=torch.bfloat16)\n",
    "inputs = tokenizer(\"technical engineering medical devices r&d risk management\", return_tensors=\"pt\")\n",
    "sample = model.generate(**inputs, max_length=128)\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text until the output length (which includes the context length) reaches 50\n",
    "input_ids = tokenizer(\"The dog\", return_tensors=\"pt\").input_ids\n",
    "gen_tokens = model.generate(input_ids, max_length=50)\n",
    "print(tokenizer.batch_decode(gen_tokens)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 329/329 [00:00<00:00, 110kB/s]\n",
      "c:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\schel\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Downloading (…)tokenization_xgen.py: 100%|██████████| 8.84k/8.84k [00:00<00:00, 8.81MB/s]\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 510/510 [00:00<00:00, 170kB/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'llama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\job_desc\\notebooks\\nb_xgen.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mSalesforce/xgen-7b-4k-base\u001b[39m\u001b[39m\"\u001b[39m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/job_desc/notebooks/nb_xgen.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mSalesforce/xgen-7b-4k-base\u001b[39;49m\u001b[39m\"\u001b[39;49m, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mbfloat16)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:434\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m hub_kwargs \u001b[39m=\u001b[39m {name: kwargs\u001b[39m.\u001b[39mpop(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m hub_kwargs_names \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m kwargs}\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 434\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    435\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    436\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    437\u001b[0m         trust_remote_code\u001b[39m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    438\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    439\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    440\u001b[0m     )\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[0;32m    442\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:873\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[39mreturn\u001b[39;00m config_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    872\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m--> 873\u001b[0m     config_class \u001b[39m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_type\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m    874\u001b[0m     \u001b[39mreturn\u001b[39;00m config_class\u001b[39m.\u001b[39mfrom_dict(config_dict, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwargs)\n\u001b[0;32m    875\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     \u001b[39m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:579\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extra_content[key]\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping:\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    580\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping[key]\n\u001b[0;32m    581\u001b[0m module_name \u001b[39m=\u001b[39m model_type_to_module_name(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'llama'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xgen-7b-4k-base\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/xgen-7b-4k-base\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The world is\", return_tensors=\"pt\")\n",
    "sample = model.generate(**inputs, max_length=128)\n",
    "print(tokenizer.decode(sample[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 20:09:29.302 No runtime found, using MemoryCacheStorageManager\n",
      "2023-09-03 20:09:31.096 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import streamlit as st\n",
    "from streamlit_folium import folium_static\n",
    "\n",
    "@st.cache_data\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path, compression='gzip', sep='\\t', quotechar='\"')\n",
    "\n",
    "housing_price_df = read_csv('../input/state_market_tracker.tsv000.gz')\n",
    "housing_price_df = housing_price_df[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy','homes_sold','state_code']]\n",
    "housing_price_df = housing_price_df[(housing_price_df['period_begin']>='2022-07-01') & (housing_price_df['period_begin']<='2023-07-01')]\n",
    "\n",
    "@st.cache_data\n",
    "def read_file(path):\n",
    "    return gpd.read_file(path)\n",
    "\n",
    "#Read the geojson file\n",
    "gdf = read_file('../input/georef-united-states-of-america-state.geojson')\n",
    "\n",
    "#Merge the housing market data and geojson file into one dataframe\n",
    "df_final = gdf.merge(housing_price_df, left_on=\"ste_stusps_code\", right_on=\"state_code\", how=\"outer\").reset_index(drop=True)\n",
    "df_final = df_final[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy',\n",
    "                     'homes_sold','state_code','ste_stusps_code','geometry']] #'ste_code','ste_name','ste_area_code','ste_type','ste_stusps_code'\n",
    "# df_final = df_final[~df_final['period_begin'].isna()].reset_index(drop=True)\n",
    "# df_final = df_final[~df_final['median_sale_price'].isna()].reset_index(drop=True)\n",
    "# df_final = df_final[~df_final['median_sale_price_yoy'].isna()].reset_index(drop=True)\n",
    "# df_final = df_final[~df_final['homes_sold'].isna()].reset_index(drop=True)\n",
    "\n",
    "# df_final = df_final.dropna(axis=0, how='any', inplace=True, subset= ['period_begin'])                     \n",
    "                                                                    # ['period_begin','property_type', 'median_sale_price', 'median_sale_price_yoy',\n",
    "                                                                    # 'homes_sold']) #.reset_index(drop=True) #, ignore_index=True)\n",
    "\n",
    "####df = df_final.drop(['ste_code', 'ste_name', 'ste_area_code', 'ste_type', 'ste_stusps_code'], axis=1)\n",
    "\n",
    "# df_final = df_final.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>property_type</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_sale_price_yoy</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>state_code</th>\n",
       "      <th>ste_stusps_code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>597700.0</td>\n",
       "      <td>-0.080654</td>\n",
       "      <td>6814.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>613000.0</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>8965.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>620500.0</td>\n",
       "      <td>-0.020862</td>\n",
       "      <td>8777.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>633600.0</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>6458.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>629900.0</td>\n",
       "      <td>0.066748</td>\n",
       "      <td>324.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_begin  period_end  period_duration              property_type  \\\n",
       "0   2023-04-01  2023-04-30             30.0            All Residential   \n",
       "1   2022-08-01  2022-08-31             30.0  Single Family Residential   \n",
       "2   2023-06-01  2023-06-30             30.0            All Residential   \n",
       "3   2023-07-01  2023-07-31             30.0  Single Family Residential   \n",
       "4   2022-11-01  2022-11-30             30.0                  Townhouse   \n",
       "\n",
       "   median_sale_price  median_sale_price_yoy  homes_sold state_code  \\\n",
       "0           597700.0              -0.080654      6814.0         WA   \n",
       "1           613000.0               0.036288      8965.0         WA   \n",
       "2           620500.0              -0.020862      8777.0         WA   \n",
       "3           633600.0               0.010260      6458.0         WA   \n",
       "4           629900.0               0.066748       324.0         WA   \n",
       "\n",
       "  ste_stusps_code                                           geometry  \n",
       "0              WA  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "1              WA  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "2              WA  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "3              WA  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "4              WA  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 3133 entries, 0 to 3132\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   period_begin           3126 non-null   object  \n",
      " 1   period_end             3126 non-null   object  \n",
      " 2   period_duration        3126 non-null   float64 \n",
      " 3   property_type          3126 non-null   object  \n",
      " 4   median_sale_price      3126 non-null   float64 \n",
      " 5   median_sale_price_yoy  3126 non-null   float64 \n",
      " 6   homes_sold             3126 non-null   float64 \n",
      " 7   state_code             3126 non-null   object  \n",
      " 8   ste_stusps_code        3133 non-null   object  \n",
      " 9   geometry               3133 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), object(5)\n",
      "memory usage: 244.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = df_final[df_final.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 3133 entries, 0 to 3132\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   period_begin           0 non-null      object  \n",
      " 1   period_end             0 non-null      object  \n",
      " 2   period_duration        0 non-null      float64 \n",
      " 3   property_type          0 non-null      object  \n",
      " 4   median_sale_price      0 non-null      float64 \n",
      " 5   median_sale_price_yoy  0 non-null      float64 \n",
      " 6   homes_sold             0 non-null      float64 \n",
      " 7   state_code             0 non-null      object  \n",
      " 8   ste_stusps_code        0 non-null      object  \n",
      " 9   geometry               0 non-null      geometry\n",
      "dtypes: float64(4), geometry(1), object(5)\n",
      "memory usage: 244.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   geo_point_2d     56 non-null     object  \n",
      " 1   year             56 non-null     object  \n",
      " 2   ste_code         56 non-null     object  \n",
      " 3   ste_name         56 non-null     object  \n",
      " 4   ste_area_code    56 non-null     object  \n",
      " 5   ste_type         56 non-null     object  \n",
      " 6   ste_stusps_code  56 non-null     object  \n",
      " 7   ste_fp_code      0 non-null      float64 \n",
      " 8   ste_gnis_code    56 non-null     object  \n",
      " 9   geometry         56 non-null     geometry\n",
      "dtypes: float64(1), geometry(1), object(8)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>property_type</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_sale_price_yoy</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>state_code</th>\n",
       "      <th>ste_stusps_code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>268700.0</td>\n",
       "      <td>-0.046864</td>\n",
       "      <td>43.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>240500.0</td>\n",
       "      <td>0.073511</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>260900.0</td>\n",
       "      <td>0.069655</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>238000.0</td>\n",
       "      <td>-0.008424</td>\n",
       "      <td>103.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>232300.0</td>\n",
       "      <td>0.119889</td>\n",
       "      <td>88.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>200700.0</td>\n",
       "      <td>-0.048134</td>\n",
       "      <td>36.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>187300.0</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>129.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>199200.0</td>\n",
       "      <td>0.165166</td>\n",
       "      <td>217.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>214800.0</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>51.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>241900.0</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     period_begin  period_end  period_duration              property_type  \\\n",
       "3123   2023-05-01  2023-05-31             30.0    Multi-Family (2-4 Unit)   \n",
       "3124   2022-09-01  2022-09-30             30.0  Single Family Residential   \n",
       "3125   2023-07-01  2023-07-31             30.0            All Residential   \n",
       "3126   2023-03-01  2023-03-31             30.0                  Townhouse   \n",
       "3127   2022-10-01  2022-10-31             30.0                  Townhouse   \n",
       "3128   2022-11-01  2022-11-30             30.0    Multi-Family (2-4 Unit)   \n",
       "3129   2023-01-01  2023-01-31             30.0                Condo/Co-op   \n",
       "3130   2022-09-01  2022-09-30             30.0                Condo/Co-op   \n",
       "3131   2022-07-01  2022-07-31             30.0    Multi-Family (2-4 Unit)   \n",
       "3132   2022-11-01  2022-11-30             30.0  Single Family Residential   \n",
       "\n",
       "      median_sale_price  median_sale_price_yoy  homes_sold state_code  \\\n",
       "3123           268700.0              -0.046864        43.0         KY   \n",
       "3124           240500.0               0.073511      4251.0         KY   \n",
       "3125           260900.0               0.069655      3973.0         KY   \n",
       "3126           238000.0              -0.008424       103.0         KY   \n",
       "3127           232300.0               0.119889        88.0         KY   \n",
       "3128           200700.0              -0.048134        36.0         KY   \n",
       "3129           187300.0               0.090090       129.0         KY   \n",
       "3130           199200.0               0.165166       217.0         KY   \n",
       "3131           214800.0               0.011690        51.0         KY   \n",
       "3132           241900.0               0.065431      3100.0         KY   \n",
       "\n",
       "     ste_stusps_code                                           geometry  \n",
       "3123              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3124              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3125              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3126              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3127              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3128              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3129              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3130              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3131              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  \n",
       "3132              KY  MULTIPOLYGON (((-89.48543 36.49749, -89.48266 ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\__python__\\_projects_\\streamlit\\redfin\\streamlit_redfin\\notebooks\\nb.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/streamlit/redfin/streamlit_redfin/notebooks/nb.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39many\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m#, subset= ['period_begin']).reset_index(drop=True)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/streamlit/redfin/streamlit_redfin/notebooks/nb.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/__python__/_projects_/streamlit/redfin/streamlit_redfin/notebooks/nb.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39minfo()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=0, how='any', inplace=True) #, subset= ['period_begin']).reset_index(drop=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.fillna(0) #.reset_index(drop=True)\n",
    "\n",
    "df_final = df_final.rename(columns={'period_begin':\"Period\",'property_type':\"Type of Property\",'median_sale_price':\"Median Sale Price\",\n",
    "                                    'median_sale_price_yoy':\"Median Sale Price YoY\",'homes_sold':\"Homes Sold\",'state_code':\"State\",\n",
    "                                    'geometry':\"Location\"})\n",
    "\n",
    "df_final[\"Median Sale Price\"] = df_final[\"Median Sale Price\"].astype(int)\n",
    "df_final[\"Median Sale Price YoY\"] = df_final[\"Median Sale Price YoY\"].astype(int)\n",
    "df_final[\"Homes Sold\"] = df_final[\"Homes Sold\"].astype(int)\n",
    "df_final[\"Month\"] = pd.to_datetime(df_final[\"Period\"], format='%Y-%m-%d').dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium.features import GeoJsonPopup, GeoJsonTooltip\n",
    "import streamlit as st\n",
    "from streamlit_folium import folium_static\n",
    "\n",
    "#@st.cache\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path, compression='gzip', sep='\\t', quotechar='\"')\n",
    "\n",
    "housing_price_df = read_csv('../input/state_market_tracker.tsv000.gz')\n",
    "housing_price_df = housing_price_df[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy','homes_sold','state_code']]\n",
    "housing_price_df = housing_price_df[(housing_price_df['period_begin']>='2022-01-01') & (housing_price_df['period_begin']<='2023-09-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = housing_price_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   period_begin           4574 non-null   object \n",
      " 1   period_end             4574 non-null   object \n",
      " 2   period_duration        4574 non-null   int64  \n",
      " 3   property_type          4574 non-null   object \n",
      " 4   median_sale_price      4574 non-null   int64  \n",
      " 5   median_sale_price_yoy  4574 non-null   float64\n",
      " 6   homes_sold             4574 non-null   int64  \n",
      " 7   state_code             4574 non-null   object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 286.0+ KB\n"
     ]
    }
   ],
   "source": [
    "hp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache\n",
    "def read_file(path):\n",
    "    return gpd.read_file(path)\n",
    "\n",
    "#Read the geojson file\n",
    "gdf = read_file('../input/georef-united-states-of-america-state.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   geo_point_2d     56 non-null     object  \n",
      " 1   year             56 non-null     object  \n",
      " 2   ste_code         56 non-null     object  \n",
      " 3   ste_name         56 non-null     object  \n",
      " 4   ste_area_code    56 non-null     object  \n",
      " 5   ste_type         56 non-null     object  \n",
      " 6   ste_stusps_code  56 non-null     object  \n",
      " 7   ste_fp_code      0 non-null      float64 \n",
      " 8   ste_gnis_code    56 non-null     object  \n",
      " 9   geometry         56 non-null     geometry\n",
      "dtypes: float64(1), geometry(1), object(8)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>year</th>\n",
       "      <th>ste_code</th>\n",
       "      <th>ste_name</th>\n",
       "      <th>ste_area_code</th>\n",
       "      <th>ste_type</th>\n",
       "      <th>ste_stusps_code</th>\n",
       "      <th>ste_fp_code</th>\n",
       "      <th>ste_gnis_code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'lon': -106.10844349925604, 'lat': 34.4212989...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[New Mexico]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00897535</td>\n",
       "      <td>POLYGON ((-106.52805 31.78389, -106.52706 31.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        geo_point_2d  year ste_code  \\\n",
       "0  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "1  {'lon': -106.10844349925604, 'lat': 34.4212989...  2022     [35]   \n",
       "\n",
       "       ste_name ste_area_code ste_type ste_stusps_code  ste_fp_code  \\\n",
       "0  [Washington]           USA    state              WA          NaN   \n",
       "1  [New Mexico]           USA    state              NM          NaN   \n",
       "\n",
       "  ste_gnis_code                                           geometry  \n",
       "0      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "1      00897535  POLYGON ((-106.52805 31.78389, -106.52706 31.7...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   period_begin           4574 non-null   object \n",
      " 1   period_end             4574 non-null   object \n",
      " 2   period_duration        4574 non-null   int64  \n",
      " 3   property_type          4574 non-null   object \n",
      " 4   median_sale_price      4574 non-null   int64  \n",
      " 5   median_sale_price_yoy  4574 non-null   float64\n",
      " 6   homes_sold             4574 non-null   int64  \n",
      " 7   state_code             4574 non-null   object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 286.0+ KB\n"
     ]
    }
   ],
   "source": [
    "hp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>property_type</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_sale_price_yoy</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>30</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>358300</td>\n",
       "      <td>0.111868</td>\n",
       "      <td>318</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>30</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>597700</td>\n",
       "      <td>-0.080654</td>\n",
       "      <td>6814</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>30</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>501000</td>\n",
       "      <td>-0.040199</td>\n",
       "      <td>3276</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>419100</td>\n",
       "      <td>0.097434</td>\n",
       "      <td>17596</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>30</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>244200</td>\n",
       "      <td>0.094606</td>\n",
       "      <td>347</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>30</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>372500</td>\n",
       "      <td>0.058123</td>\n",
       "      <td>1309</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>30</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>296000</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>3</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>507800</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>7323</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>30</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>313800</td>\n",
       "      <td>-0.049445</td>\n",
       "      <td>83</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>30</td>\n",
       "      <td>Multi-Family (2-4 Unit)</td>\n",
       "      <td>178600</td>\n",
       "      <td>-0.052272</td>\n",
       "      <td>42</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   period_begin  period_end  period_duration              property_type  \\\n",
       "0    2022-08-01  2022-08-31               30    Multi-Family (2-4 Unit)   \n",
       "1    2023-04-01  2023-04-30               30            All Residential   \n",
       "2    2023-03-01  2023-03-31               30  Single Family Residential   \n",
       "3    2022-11-01  2022-11-30               30  Single Family Residential   \n",
       "4    2022-02-01  2022-02-28               30                Condo/Co-op   \n",
       "..          ...         ...              ...                        ...   \n",
       "59   2023-05-01  2023-05-31               30            All Residential   \n",
       "60   2022-04-01  2022-04-30               30                  Townhouse   \n",
       "61   2023-06-01  2023-06-30               30  Single Family Residential   \n",
       "62   2023-02-01  2023-02-28               30                Condo/Co-op   \n",
       "63   2022-01-01  2022-01-31               30    Multi-Family (2-4 Unit)   \n",
       "\n",
       "    median_sale_price  median_sale_price_yoy  homes_sold state_code  \n",
       "0              358300               0.111868         318         TX  \n",
       "1              597700              -0.080654        6814         WA  \n",
       "2              501000              -0.040199        3276         OR  \n",
       "3              419100               0.097434       17596         FL  \n",
       "4              244200               0.094606         347         PA  \n",
       "..                ...                    ...         ...        ...  \n",
       "59             372500               0.058123        1309         ME  \n",
       "60             296000               0.008518           3         RI  \n",
       "61             507800               0.032561        7323         NJ  \n",
       "62             313800              -0.049445          83         RI  \n",
       "63             178600              -0.052272          42         OK  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_df.head(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the housing market data and geojson file into one dataframe\n",
    "df_final = gdf.merge(hp_df, left_on=\"ste_stusps_code\", right_on=\"state_code\", how=\"outer\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>year</th>\n",
       "      <th>ste_code</th>\n",
       "      <th>ste_name</th>\n",
       "      <th>ste_area_code</th>\n",
       "      <th>ste_type</th>\n",
       "      <th>ste_stusps_code</th>\n",
       "      <th>ste_fp_code</th>\n",
       "      <th>ste_gnis_code</th>\n",
       "      <th>geometry</th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>property_type</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_sale_price_yoy</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>597700.0</td>\n",
       "      <td>-0.080654</td>\n",
       "      <td>6814.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>579800.0</td>\n",
       "      <td>0.154859</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>613000.0</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>8965.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>687000.0</td>\n",
       "      <td>0.129715</td>\n",
       "      <td>687.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>620500.0</td>\n",
       "      <td>-0.020862</td>\n",
       "      <td>8777.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>653600.0</td>\n",
       "      <td>0.141186</td>\n",
       "      <td>11878.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>436600.0</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>713.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>567800.0</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>3487.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Condo/Co-op</td>\n",
       "      <td>402200.0</td>\n",
       "      <td>0.175419</td>\n",
       "      <td>627.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>{'lon': -120.5928034897229, 'lat': 47.41161380...</td>\n",
       "      <td>2022</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01779804</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>553400.0</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         geo_point_2d  year ste_code  \\\n",
       "0   {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "1   {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "2   {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "3   {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "4   {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "..                                                ...   ...      ...   \n",
       "59  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "60  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "61  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "62  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "63  {'lon': -120.5928034897229, 'lat': 47.41161380...  2022     [53]   \n",
       "\n",
       "        ste_name ste_area_code ste_type ste_stusps_code  ste_fp_code  \\\n",
       "0   [Washington]           USA    state              WA          NaN   \n",
       "1   [Washington]           USA    state              WA          NaN   \n",
       "2   [Washington]           USA    state              WA          NaN   \n",
       "3   [Washington]           USA    state              WA          NaN   \n",
       "4   [Washington]           USA    state              WA          NaN   \n",
       "..           ...           ...      ...             ...          ...   \n",
       "59  [Washington]           USA    state              WA          NaN   \n",
       "60  [Washington]           USA    state              WA          NaN   \n",
       "61  [Washington]           USA    state              WA          NaN   \n",
       "62  [Washington]           USA    state              WA          NaN   \n",
       "63  [Washington]           USA    state              WA          NaN   \n",
       "\n",
       "   ste_gnis_code                                           geometry  \\\n",
       "0       01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "1       01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "2       01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "3       01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "4       01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "..           ...                                                ...   \n",
       "59      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "60      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "61      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "62      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "63      01779804  POLYGON ((-117.03235 48.99920, -117.13490 48.9...   \n",
       "\n",
       "   period_begin  period_end  period_duration              property_type  \\\n",
       "0    2023-04-01  2023-04-30             30.0            All Residential   \n",
       "1    2022-02-01  2022-02-28             30.0            All Residential   \n",
       "2    2022-08-01  2022-08-31             30.0  Single Family Residential   \n",
       "3    2022-05-01  2022-05-31             30.0                  Townhouse   \n",
       "4    2023-06-01  2023-06-30             30.0            All Residential   \n",
       "..          ...         ...              ...                        ...   \n",
       "59   2022-05-01  2022-05-31             30.0            All Residential   \n",
       "60   2023-07-01  2023-07-31             30.0                Condo/Co-op   \n",
       "61   2023-01-01  2023-01-31             30.0  Single Family Residential   \n",
       "62   2022-01-01  2022-01-31             30.0                Condo/Co-op   \n",
       "63   2023-01-01  2023-01-31             30.0            All Residential   \n",
       "\n",
       "    median_sale_price  median_sale_price_yoy  homes_sold state_code  \n",
       "0            597700.0              -0.080654      6814.0         WA  \n",
       "1            579800.0               0.154859      7148.0         WA  \n",
       "2            613000.0               0.036288      8965.0         WA  \n",
       "3            687000.0               0.129715       687.0         WA  \n",
       "4            620500.0              -0.020862      8777.0         WA  \n",
       "..                ...                    ...         ...        ...  \n",
       "59           653600.0               0.141186     11878.0         WA  \n",
       "60           436600.0               0.018121       713.0         WA  \n",
       "61           567800.0               0.027200      3487.0         WA  \n",
       "62           402200.0               0.175419       627.0         WA  \n",
       "63           553400.0               0.011500      4187.0         WA  \n",
       "\n",
       "[64 rows x 18 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the housing market data and geojson file into one dataframe\n",
    "df_final = gdf.merge(hp_df, left_on=\"ste_stusps_code\", right_on=\"state_code\", how=\"outer\").reset_index(drop=True)\n",
    "df_final = df_final[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy','homes_sold',\n",
    "                     'state_code', 'ste_code','ste_name', 'ste_area_code', 'ste_type', 'ste_stusps_code','geometry']]\n",
    "df_final = df_final[~df_final['period_begin'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add sidebar to the app\n",
    "st.sidebar.markdown(\"### Redfin Housing Data\")\n",
    "st.sidebar.markdown(\"This app is built using Streamlit to help visualize activity in the U.S. real estate market. All data from: https://www.redfin.com/news/data-center/\")\n",
    "st.sidebar.markdown(\"Developed by Robert Schell: https://github.com/schellrw\")\n",
    "#Add title and subtitle to the main interface of the app\n",
    "st.title(\"U.S. Real Estate Activity Heatmap\")\n",
    "st.markdown(\"Where are the hottest housing markets in the U.S.? Select the housing market metrics you are interested in and your insights are just a couple clicks away. Hover over the map to view more details.\")\n",
    "\n",
    "#Create three columns/filters\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "     period_list = df_final[\"period_begin\"].unique().tolist()\n",
    "     period_list.sort(reverse=True)\n",
    "     year_month = st.selectbox(\"Snapshot Month\", period_list, index=0)\n",
    "\n",
    "with col2:\n",
    "     prop_type = st.selectbox(\n",
    "                \"View by Property Type\", ['All Residential', 'Single Family Residential', 'Townhouse','Condo/Co-op','Single Units Only','Multi-Family (2-4 Unit)'] , index=0)\n",
    "\n",
    "with col3:\n",
    "     metrics = st.selectbox(\"Select Housing Metrics\", [\"median_sale_price\",\"median_sale_price_yoy\", \"homes_sold\"], index=0)\n",
    "\n",
    "#Update the data frame accordingly based on user input\n",
    "df = df[df[\"period_begin\"]==year_month]\n",
    "df = df[df[\"property_type\"]==prop_type]\n",
    "df = df[['period_begin','period_end','period_duration','property_type',metrics,'state_code','ste_code','ste_name','ste_area_code','ste_type','ste_stusps_code','geometry']]\n",
    "\n",
    "#st.write(df)\n",
    "\n",
    "#Initiate a folium map\n",
    "m = folium.Map(location=[40, -100], zoom_start=4,tiles=None)\n",
    "folium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n",
    "\n",
    "#Plot Choropleth map using folium\n",
    "choropleth1 = folium.Choropleth(\n",
    "    geo_data='./us-state-boundaries.geojson',       # Geojson file for the United States\n",
    "    name='Choropleth Map of U.S. Housing Prices',\n",
    "    data=df,                                        # df from the data preparation and user selection\n",
    "    columns=['state_code', metrics],                # 'state code' and 'metrics' are the two columns in the dataframe that we use to grab the median sales price for each state and plot it in the choropleth map\n",
    "    key_on='feature.properties.ste_stusps_code',    # key in the geojson file that we use to grab the geometries for each state in order to add the geographical boundary layers to the map\n",
    "    fill_color='YlGn',\n",
    "    nan_fill_color=\"White\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Housing Market Metrics',\n",
    "    highlight=True,\n",
    "    line_color='black').geojson.add_to(m)\n",
    "\n",
    "#Add tooltips to the map\n",
    "geojson1 = folium.features.GeoJson(\n",
    "               data=df,\n",
    "               name='United States Housing Prices',\n",
    "               smooth_factor=2,\n",
    "               style_function=lambda x: {'color':'black','fillColor':'transparent','weight':0.5},\n",
    "               tooltip=folium.features.GeoJsonTooltip(\n",
    "                   fields=['period_begin',\n",
    "                           'period_end',\n",
    "                           'name',\n",
    "                           metrics,],\n",
    "                   aliases=[\"Period Begin:\",\n",
    "                            'Period End:',\n",
    "                            'State:',\n",
    "                            metrics+\":\"],\n",
    "                   localize=True,\n",
    "                   sticky=False,\n",
    "                   labels=True,\n",
    "                   style=\"\"\"\n",
    "                       background-color: #F0EFEF;\n",
    "                       border: 2px solid black;\n",
    "                       border-radius: 3px;\n",
    "                       box-shadow: 3px;\n",
    "                   \"\"\",\n",
    "                   max_width=800,),\n",
    "                    highlight_function=lambda x: {'weight':3,'fillColor':'grey'},\n",
    "                   ).add_to(m)\n",
    "#folium_static(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 14:20:31.062 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 14:20:32.412 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium.features import GeoJsonPopup, GeoJsonTooltip\n",
    "import streamlit as st\n",
    "from streamlit_folium import folium_static\n",
    "\n",
    "@st.cache_data\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path, compression='gzip', sep='\\t', quotechar='\"')\n",
    "\n",
    "housing_price_df = read_csv('../input/state_market_tracker.tsv000.gz')\n",
    "housing_price_df = housing_price_df[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy','homes_sold','state_code']]\n",
    "housing_price_df = housing_price_df[(housing_price_df['period_begin']>='2022-01-01') & (housing_price_df['period_begin']<='2023-07-01')]\n",
    "\n",
    "@st.cache_data\n",
    "def read_file(path):\n",
    "    return gpd.read_file(path)\n",
    "\n",
    "#Read the geojson file\n",
    "# gdf = read_file('./input/georef-united-states-of-america-state.geojson')\n",
    "gdf = read_file('../input/georef-united-states-of-america-state.geojson')\n",
    "\n",
    "#Merge the housing market data and geojson file into one dataframe\n",
    "df_final = gdf.merge(housing_price_df, left_on=\"ste_stusps_code\", right_on=\"state_code\", how=\"outer\").reset_index(drop=True)\n",
    "df_final = df_final[['period_begin','period_end','period_duration','property_type','median_sale_price','median_sale_price_yoy','homes_sold',\n",
    "                     'state_code','ste_code','ste_name','ste_area_code','ste_type','ste_stusps_code','geometry']]\n",
    "df_final = df_final[~df_final['period_begin'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   period_begin           4574 non-null   object  \n",
      " 1   period_end             4574 non-null   object  \n",
      " 2   period_duration        4574 non-null   float64 \n",
      " 3   property_type          4574 non-null   object  \n",
      " 4   median_sale_price      4574 non-null   float64 \n",
      " 5   median_sale_price_yoy  4574 non-null   float64 \n",
      " 6   homes_sold             4574 non-null   float64 \n",
      " 7   state_code             4574 non-null   object  \n",
      " 8   ste_code               4574 non-null   object  \n",
      " 9   ste_name               4574 non-null   object  \n",
      " 10  ste_area_code          4574 non-null   object  \n",
      " 11  ste_type               4574 non-null   object  \n",
      " 12  ste_stusps_code        4574 non-null   object  \n",
      " 13  geometry               4574 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), object(9)\n",
      "memory usage: 500.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>property_type</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_sale_price_yoy</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>state_code</th>\n",
       "      <th>ste_code</th>\n",
       "      <th>ste_name</th>\n",
       "      <th>ste_area_code</th>\n",
       "      <th>ste_type</th>\n",
       "      <th>ste_stusps_code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>597700.0</td>\n",
       "      <td>-0.080654</td>\n",
       "      <td>6814.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>579800.0</td>\n",
       "      <td>0.154859</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>[53]</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>USA</td>\n",
       "      <td>state</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_begin  period_end  period_duration    property_type  \\\n",
       "0   2023-04-01  2023-04-30             30.0  All Residential   \n",
       "1   2022-02-01  2022-02-28             30.0  All Residential   \n",
       "\n",
       "   median_sale_price  median_sale_price_yoy  homes_sold state_code ste_code  \\\n",
       "0           597700.0              -0.080654      6814.0         WA     [53]   \n",
       "1           579800.0               0.154859      7148.0         WA     [53]   \n",
       "\n",
       "       ste_name ste_area_code ste_type ste_stusps_code  \\\n",
       "0  [Washington]           USA    state              WA   \n",
       "1  [Washington]           USA    state              WA   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "1  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   period_begin           4574 non-null   object  \n",
      " 1   period_end             4574 non-null   object  \n",
      " 2   period_duration        4574 non-null   float64 \n",
      " 3   property_type          4574 non-null   object  \n",
      " 4   median_sale_price      4574 non-null   float64 \n",
      " 5   median_sale_price_yoy  4574 non-null   float64 \n",
      " 6   homes_sold             4574 non-null   float64 \n",
      " 7   state_code             4574 non-null   object  \n",
      " 8   ste_code               4574 non-null   object  \n",
      " 9   ste_name               4574 non-null   object  \n",
      " 10  ste_area_code          4574 non-null   object  \n",
      " 11  ste_type               4574 non-null   object  \n",
      " 12  ste_stusps_code        4574 non-null   object  \n",
      " 13  geometry               4574 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), object(9)\n",
      "memory usage: 500.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   period_begin           4574 non-null   object  \n",
      " 1   period_end             4574 non-null   object  \n",
      " 2   period_duration        4574 non-null   float64 \n",
      " 3   property_type          4574 non-null   object  \n",
      " 4   median_sale_price      4574 non-null   float64 \n",
      " 5   median_sale_price_yoy  4574 non-null   float64 \n",
      " 6   homes_sold             4574 non-null   float64 \n",
      " 7   state_code             4574 non-null   object  \n",
      " 8   ste_code               4574 non-null   object  \n",
      " 9   ste_name               4574 non-null   object  \n",
      " 10  ste_area_code          4574 non-null   object  \n",
      " 11  ste_type               4574 non-null   object  \n",
      " 12  ste_stusps_code        4574 non-null   object  \n",
      " 13  geometry               4574 non-null   geometry\n",
      "dtypes: float64(4), geometry(1), object(9)\n",
      "memory usage: 500.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim = df_final.drop(['ste_code', 'ste_name', 'ste_area_code', 'ste_type', 'ste_stusps_code'], axis=1)\n",
    "df_slim = df_slim.rename(columns={'property_type':\"Type of Property\",'median_sale_price':\"Median Sale Price\",'median_sale_price_yoy':\"Median Sale Price YoY\",\n",
    "                            'homes_sold':\"Homes Sold\",'state_code':\"State\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>Type of Property</th>\n",
       "      <th>Median Sale Price</th>\n",
       "      <th>Median Sale Price YoY</th>\n",
       "      <th>Homes Sold</th>\n",
       "      <th>State</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>597700.0</td>\n",
       "      <td>-0.080654</td>\n",
       "      <td>6814.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>30.0</td>\n",
       "      <td>All Residential</td>\n",
       "      <td>579800.0</td>\n",
       "      <td>0.154859</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>POLYGON ((-117.03235 48.99920, -117.13490 48.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  period_begin  period_end  period_duration Type of Property  \\\n",
       "0   2023-04-01  2023-04-30             30.0  All Residential   \n",
       "1   2022-02-01  2022-02-28             30.0  All Residential   \n",
       "\n",
       "   Median Sale Price  Median Sale Price YoY  Homes Sold State  \\\n",
       "0           597700.0              -0.080654      6814.0    WA   \n",
       "1           579800.0               0.154859      7148.0    WA   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  \n",
       "1  POLYGON ((-117.03235 48.99920, -117.13490 48.9...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
